---
title: "speleologia"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

require(progress, quietly = T)
require(ggplot2)
require(data.table, quietly = T)
require(kernlab, quietly = T)
require(e1071, quietly = T)
require(caret, quietly = T)
require(randomForest, quietly = T)
library(xgboost)
library(tidymodels)
library(tidyverse)
library(viridis)
library(stacks)
library(vip)
library(isotree)
library(iml)


dataset = fread(file = "ahshitherewegoagain2.csv")
data = dataset[,-'nation']
data = data[,-'id']
data = data[,-'producer']
data = data[,-'name']
data = data[,-'ml']
data = data[,-'price']
data = data[,-'year']
data = data[,-'latitudine']
data = data[,-'longitudine']
data = data[,-'degree']
data = data[,-(24:31)]
data = data[,-'acidity']
data = data[,-'sweet']
data[,'local1'] = as.factor(data[['local1']])


set.seed(420)
iso <- isolation.forest(data[,-c('score')], ntrees = 10, nthreads = 1)

### Check which row has the highest outlier score
pred <- predict(iso, data[,-c('score')])

data = data[which(pred <= 0.50), ]


X = data[,-c('score')]
y = data[,'score']




train_idx = sample(1:dim(data)[1], replace = FALSE, size = floor(0.8 * dim(data)[1]))

X_train = X[train_idx,]
y_train = y[train_idx,]
X_val = X[-train_idx,]
y_val = y[-train_idx,]

vini_train = data.frame(X_train, score = y_train)
vini_test = data.frame(X_val, score = y_val)


vini_folds <- vfold_cv(vini_train, strata = score, v = 5)
contrl_preds <- control_resamples(save_pred = TRUE)
vini_formula <- score ~ .


# nuovini
new_dataset = fread(file = "prcmdnn.csv")
new_data = new_dataset[,2:29]
new_data = new_data[,-'Nation']
new_data = new_data[,-'Producer']
new_data = new_data[,-'Name']
new_data = new_data[,-'year']
new_data = new_data[,-'latitudine']
new_data = new_data[,-'longitudine']
new_data = new_data[, colnames(data), with = FALSE]
new_data[,'local1'] = factor(new_data[['local1']], levels = levels(data[['local1']]))

X_new = as.data.frame(new_data[,-'score'])
X_new[,'local1'] = factor(X_new[['local1']], levels = levels(data[['local1']]))
y_new = as.data.frame(new_data[,'score'])



rec = recipe( vini_formula, data = data) %>%
  step_normalize(all_numeric_predictors())

rec2 = recipe( vini_formula, data = data) %>%
  step_rm(contains("local1")) %>%
  step_normalize(all_numeric_predictors())

bootstraps = bootstraps(data)

```










```{r linear}

lm_spec <-
  linear_reg() %>% 
  set_engine("lm")

lm_wf    <- workflow() %>% add_model(lm_spec) %>% add_recipe(rec)

lm_model <- fit(lm_wf, data)


```



```{r xgboost}


# tuning
boost_spec <- boost_tree(
                          mode = "regression",
                          engine = "xgboost",
                          mtry = tune(),
                          trees = tune(),
                          min_n = tune(),
                          tree_depth = tune())



boost_wf    <- workflow() %>% add_model(boost_spec) %>% add_recipe(rec2)

grid = tune_grid(boost_wf, resamples = bootstraps)

show_best(grid, 'rmse')


# fit best model
boost_spec <- boost_tree(
                          mode = "regression",
                          engine = "xgboost",
                          mtry = select_best(grid, metric = 'rmse')$mtry,
                          trees = select_best(grid, metric = 'rmse')$trees,
                          min_n = select_best(grid, metric = 'rmse')$min_n,
                          tree_depth = select_best(grid, metric = 'rmse')$tree_depth)

boost_wf    <- workflow() %>% add_model(boost_spec) %>% add_recipe(rec2)

xg_model <- fit(boost_wf, data)



```


```{r random forest}

# tuning
ranger_spec <-
  rand_forest(trees = tune(), mtry = tune(), min_n = tune()) %>%
  set_engine("ranger") %>%
  set_mode("regression")


ranger_wf    <- workflow() %>% add_model(ranger_spec) %>% add_recipe(rec)

grid = tune_grid(ranger_wf, resamples = bootstraps)

show_best(grid, 'rmse')


# fit best model
ranger_spec <-
  rand_forest(trees = select_best(grid, metric = 'rmse')$trees, mtry = select_best(grid, metric = 'rmse')$mtry, min_n = select_best(grid, metric = 'rmse')$min_n) %>%
  set_engine("ranger") %>%
  set_mode("regression")

ranger_wf    <- workflow() %>% add_model(ranger_spec) %>% add_recipe(rec)

rf_model <- fit(ranger_wf, data)


```

```{r radial svm}

# tuning
svm_spec <- svm_rbf(
                    mode = "regression",
                    engine = "kernlab",
                    cost = tune(),
                    rbf_sigma = tune(),
                    margin = tune())


svm_wf    <- workflow() %>% add_model(svm_spec) %>% add_recipe(rec2)

grid = tune_grid(svm_wf, resamples = bootstraps)

show_best(grid, 'rmse')


# fit best model
svm_spec <- svm_rbf(
                    mode = "regression",
                    engine = "kernlab",
                    cost = select_best(grid, metric = 'rmse')$cost,
                    rbf_sigma = select_best(grid, metric = 'rmse')$rbf_sigma,
                    margin = select_best(grid, metric = 'rmse')$margin)


svm_wf    <- workflow() %>% add_model(svm_spec) %>% add_recipe(rec2)

svm_model <- fit(svm_wf, data)

```





```{r}



predictor <- Predictor$new(lm_model, data = X_train, y = y_train)

imp <- FeatureImp$new(predictor, loss = "mse")

plot(imp)


ale <- FeatureEffect$new(predictor, feature = "sand")
ale$plot()


interact <- Interaction$new(predictor)
plot(interact)



interact <- Interaction$new(predictor, feature = "sand")
plot(interact)




effs <- FeatureEffects$new(predictor)
plot(effs)



tree <- TreeSurrogate$new(predictor, maxdepth = 2)
plot(tree)



```

```{python}

import pandas as pd

pd.DataFrame(['Cazzo'])



```




```{r}




lime.explain <- LocalModel$new(predictor, x.interest = X_new[1,])


lime.explain$results

plot(lime.explain)

caret::RMSE(as.matrix(predict(lm_model, X_new)), as.matrix(y_new))


shapley <- Shapley$new(predictor, x.interest = X_new[1, ])
shapley$plot()

```

